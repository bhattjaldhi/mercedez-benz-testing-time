{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1.1: Linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# Step 1.2: Data processing\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1.3: For dimensionality reduction\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Read the data from train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4209 entries, 0 to 4208\n",
      "Columns: 378 entries, ID to X385\n",
      "dtypes: float64(1), int64(369), object(8)\n",
      "memory usage: 12.1+ MB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "                 ID            y          X10     X11          X12  \\\n",
      "count  4209.000000  4209.000000  4209.000000  4209.0  4209.000000   \n",
      "mean   4205.960798   100.669318     0.013305     0.0     0.075077   \n",
      "std    2437.608688    12.679381     0.114590     0.0     0.263547   \n",
      "min       0.000000    72.110000     0.000000     0.0     0.000000   \n",
      "25%    2095.000000    90.820000     0.000000     0.0     0.000000   \n",
      "50%    4220.000000    99.150000     0.000000     0.0     0.000000   \n",
      "75%    6314.000000   109.010000     0.000000     0.0     0.000000   \n",
      "max    8417.000000   265.320000     1.000000     0.0     1.000000   \n",
      "\n",
      "               X13          X14          X15          X16          X17  ...  \\\n",
      "count  4209.000000  4209.000000  4209.000000  4209.000000  4209.000000  ...   \n",
      "mean      0.057971     0.428130     0.000475     0.002613     0.007603  ...   \n",
      "std       0.233716     0.494867     0.021796     0.051061     0.086872  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "75%       0.000000     1.000000     0.000000     0.000000     0.000000  ...   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
      "\n",
      "              X375         X376         X377         X378         X379  \\\n",
      "count  4209.000000  4209.000000  4209.000000  4209.000000  4209.000000   \n",
      "mean      0.318841     0.057258     0.314802     0.020670     0.009503   \n",
      "std       0.466082     0.232363     0.464492     0.142294     0.097033   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       1.000000     0.000000     1.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "              X380         X382         X383         X384         X385  \n",
      "count  4209.000000  4209.000000  4209.000000  4209.000000  4209.000000  \n",
      "mean      0.008078     0.007603     0.001663     0.000475     0.001426  \n",
      "std       0.089524     0.086872     0.040752     0.021796     0.037734  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
      "\n",
      "[8 rows x 370 columns]\n",
      "\n",
      "Unique Values in Each Column:\n",
      " ID      4209\n",
      "y       2545\n",
      "X0        47\n",
      "X1        27\n",
      "X2        44\n",
      "        ... \n",
      "X380       2\n",
      "X382       2\n",
      "X383       2\n",
      "X384       2\n",
      "X385       2\n",
      "Length: 378, dtype: int64\n",
      "\n",
      "First 5 Rows of the Data:\n",
      "    ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
      "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
      "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
      "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
      "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
      "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
      "\n",
      "   X380  X382  X383  X384  X385  \n",
      "0     0     0     0     0     0  \n",
      "1     0     0     0     0     0  \n",
      "2     0     1     0     0     0  \n",
      "3     0     0     0     0     0  \n",
      "4     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 378 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming your file is named 'train.csv'\n",
    "file_path = './train.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2.1: Let us understand the data\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\\n\")\n",
    "print(data.info())\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary Statistics:\\n\", data.describe())\n",
    "\n",
    "# Display the unique values in each column\n",
    "print(\"\\nUnique Values in Each Column:\\n\", data.nunique())\n",
    "\n",
    "# Step 2.2: Print a few rows and see how the data looks like\n",
    "print(\"\\nFirst 5 Rows of the Data:\\n\", data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Collect the Y values into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (4209, 376)\n",
      "Shape of y: (4209,)\n"
     ]
    }
   ],
   "source": [
    "# Step 3.1: Separate the y from the data\n",
    "\n",
    "# Assuming your target variable (Y) is named 'target_column'\n",
    "target_column = 'y'  # Replace with your actual target column name\n",
    "\n",
    "# Separate the target variable from the rest of the data\n",
    "y = data[target_column]\n",
    "\n",
    "# Drop the target column from the original data\n",
    "X = data.drop(columns=[target_column, 'ID'])\n",
    "\n",
    "# Display the shape of X and y\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Understand the data types we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types of Columns with 'X':\n",
      "X0: object\n",
      "X1: object\n",
      "X2: object\n",
      "X3: object\n",
      "X4: object\n",
      "X5: object\n",
      "X6: object\n",
      "X8: object\n",
      "X10: int64\n",
      "X11: int64\n",
      "X12: int64\n",
      "X13: int64\n",
      "X14: int64\n",
      "X15: int64\n",
      "X16: int64\n",
      "X17: int64\n",
      "X18: int64\n",
      "X19: int64\n",
      "X20: int64\n",
      "X21: int64\n",
      "X22: int64\n",
      "X23: int64\n",
      "X24: int64\n",
      "X26: int64\n",
      "X27: int64\n",
      "X28: int64\n",
      "X29: int64\n",
      "X30: int64\n",
      "X31: int64\n",
      "X32: int64\n",
      "X33: int64\n",
      "X34: int64\n",
      "X35: int64\n",
      "X36: int64\n",
      "X37: int64\n",
      "X38: int64\n",
      "X39: int64\n",
      "X40: int64\n",
      "X41: int64\n",
      "X42: int64\n",
      "X43: int64\n",
      "X44: int64\n",
      "X45: int64\n",
      "X46: int64\n",
      "X47: int64\n",
      "X48: int64\n",
      "X49: int64\n",
      "X50: int64\n",
      "X51: int64\n",
      "X52: int64\n",
      "X53: int64\n",
      "X54: int64\n",
      "X55: int64\n",
      "X56: int64\n",
      "X57: int64\n",
      "X58: int64\n",
      "X59: int64\n",
      "X60: int64\n",
      "X61: int64\n",
      "X62: int64\n",
      "X63: int64\n",
      "X64: int64\n",
      "X65: int64\n",
      "X66: int64\n",
      "X67: int64\n",
      "X68: int64\n",
      "X69: int64\n",
      "X70: int64\n",
      "X71: int64\n",
      "X73: int64\n",
      "X74: int64\n",
      "X75: int64\n",
      "X76: int64\n",
      "X77: int64\n",
      "X78: int64\n",
      "X79: int64\n",
      "X80: int64\n",
      "X81: int64\n",
      "X82: int64\n",
      "X83: int64\n",
      "X84: int64\n",
      "X85: int64\n",
      "X86: int64\n",
      "X87: int64\n",
      "X88: int64\n",
      "X89: int64\n",
      "X90: int64\n",
      "X91: int64\n",
      "X92: int64\n",
      "X93: int64\n",
      "X94: int64\n",
      "X95: int64\n",
      "X96: int64\n",
      "X97: int64\n",
      "X98: int64\n",
      "X99: int64\n",
      "X100: int64\n",
      "X101: int64\n",
      "X102: int64\n",
      "X103: int64\n",
      "X104: int64\n",
      "X105: int64\n",
      "X106: int64\n",
      "X107: int64\n",
      "X108: int64\n",
      "X109: int64\n",
      "X110: int64\n",
      "X111: int64\n",
      "X112: int64\n",
      "X113: int64\n",
      "X114: int64\n",
      "X115: int64\n",
      "X116: int64\n",
      "X117: int64\n",
      "X118: int64\n",
      "X119: int64\n",
      "X120: int64\n",
      "X122: int64\n",
      "X123: int64\n",
      "X124: int64\n",
      "X125: int64\n",
      "X126: int64\n",
      "X127: int64\n",
      "X128: int64\n",
      "X129: int64\n",
      "X130: int64\n",
      "X131: int64\n",
      "X132: int64\n",
      "X133: int64\n",
      "X134: int64\n",
      "X135: int64\n",
      "X136: int64\n",
      "X137: int64\n",
      "X138: int64\n",
      "X139: int64\n",
      "X140: int64\n",
      "X141: int64\n",
      "X142: int64\n",
      "X143: int64\n",
      "X144: int64\n",
      "X145: int64\n",
      "X146: int64\n",
      "X147: int64\n",
      "X148: int64\n",
      "X150: int64\n",
      "X151: int64\n",
      "X152: int64\n",
      "X153: int64\n",
      "X154: int64\n",
      "X155: int64\n",
      "X156: int64\n",
      "X157: int64\n",
      "X158: int64\n",
      "X159: int64\n",
      "X160: int64\n",
      "X161: int64\n",
      "X162: int64\n",
      "X163: int64\n",
      "X164: int64\n",
      "X165: int64\n",
      "X166: int64\n",
      "X167: int64\n",
      "X168: int64\n",
      "X169: int64\n",
      "X170: int64\n",
      "X171: int64\n",
      "X172: int64\n",
      "X173: int64\n",
      "X174: int64\n",
      "X175: int64\n",
      "X176: int64\n",
      "X177: int64\n",
      "X178: int64\n",
      "X179: int64\n",
      "X180: int64\n",
      "X181: int64\n",
      "X182: int64\n",
      "X183: int64\n",
      "X184: int64\n",
      "X185: int64\n",
      "X186: int64\n",
      "X187: int64\n",
      "X189: int64\n",
      "X190: int64\n",
      "X191: int64\n",
      "X192: int64\n",
      "X194: int64\n",
      "X195: int64\n",
      "X196: int64\n",
      "X197: int64\n",
      "X198: int64\n",
      "X199: int64\n",
      "X200: int64\n",
      "X201: int64\n",
      "X202: int64\n",
      "X203: int64\n",
      "X204: int64\n",
      "X205: int64\n",
      "X206: int64\n",
      "X207: int64\n",
      "X208: int64\n",
      "X209: int64\n",
      "X210: int64\n",
      "X211: int64\n",
      "X212: int64\n",
      "X213: int64\n",
      "X214: int64\n",
      "X215: int64\n",
      "X216: int64\n",
      "X217: int64\n",
      "X218: int64\n",
      "X219: int64\n",
      "X220: int64\n",
      "X221: int64\n",
      "X222: int64\n",
      "X223: int64\n",
      "X224: int64\n",
      "X225: int64\n",
      "X226: int64\n",
      "X227: int64\n",
      "X228: int64\n",
      "X229: int64\n",
      "X230: int64\n",
      "X231: int64\n",
      "X232: int64\n",
      "X233: int64\n",
      "X234: int64\n",
      "X235: int64\n",
      "X236: int64\n",
      "X237: int64\n",
      "X238: int64\n",
      "X239: int64\n",
      "X240: int64\n",
      "X241: int64\n",
      "X242: int64\n",
      "X243: int64\n",
      "X244: int64\n",
      "X245: int64\n",
      "X246: int64\n",
      "X247: int64\n",
      "X248: int64\n",
      "X249: int64\n",
      "X250: int64\n",
      "X251: int64\n",
      "X252: int64\n",
      "X253: int64\n",
      "X254: int64\n",
      "X255: int64\n",
      "X256: int64\n",
      "X257: int64\n",
      "X258: int64\n",
      "X259: int64\n",
      "X260: int64\n",
      "X261: int64\n",
      "X262: int64\n",
      "X263: int64\n",
      "X264: int64\n",
      "X265: int64\n",
      "X266: int64\n",
      "X267: int64\n",
      "X268: int64\n",
      "X269: int64\n",
      "X270: int64\n",
      "X271: int64\n",
      "X272: int64\n",
      "X273: int64\n",
      "X274: int64\n",
      "X275: int64\n",
      "X276: int64\n",
      "X277: int64\n",
      "X278: int64\n",
      "X279: int64\n",
      "X280: int64\n",
      "X281: int64\n",
      "X282: int64\n",
      "X283: int64\n",
      "X284: int64\n",
      "X285: int64\n",
      "X286: int64\n",
      "X287: int64\n",
      "X288: int64\n",
      "X289: int64\n",
      "X290: int64\n",
      "X291: int64\n",
      "X292: int64\n",
      "X293: int64\n",
      "X294: int64\n",
      "X295: int64\n",
      "X296: int64\n",
      "X297: int64\n",
      "X298: int64\n",
      "X299: int64\n",
      "X300: int64\n",
      "X301: int64\n",
      "X302: int64\n",
      "X304: int64\n",
      "X305: int64\n",
      "X306: int64\n",
      "X307: int64\n",
      "X308: int64\n",
      "X309: int64\n",
      "X310: int64\n",
      "X311: int64\n",
      "X312: int64\n",
      "X313: int64\n",
      "X314: int64\n",
      "X315: int64\n",
      "X316: int64\n",
      "X317: int64\n",
      "X318: int64\n",
      "X319: int64\n",
      "X320: int64\n",
      "X321: int64\n",
      "X322: int64\n",
      "X323: int64\n",
      "X324: int64\n",
      "X325: int64\n",
      "X326: int64\n",
      "X327: int64\n",
      "X328: int64\n",
      "X329: int64\n",
      "X330: int64\n",
      "X331: int64\n",
      "X332: int64\n",
      "X333: int64\n",
      "X334: int64\n",
      "X335: int64\n",
      "X336: int64\n",
      "X337: int64\n",
      "X338: int64\n",
      "X339: int64\n",
      "X340: int64\n",
      "X341: int64\n",
      "X342: int64\n",
      "X343: int64\n",
      "X344: int64\n",
      "X345: int64\n",
      "X346: int64\n",
      "X347: int64\n",
      "X348: int64\n",
      "X349: int64\n",
      "X350: int64\n",
      "X351: int64\n",
      "X352: int64\n",
      "X353: int64\n",
      "X354: int64\n",
      "X355: int64\n",
      "X356: int64\n",
      "X357: int64\n",
      "X358: int64\n",
      "X359: int64\n",
      "X360: int64\n",
      "X361: int64\n",
      "X362: int64\n",
      "X363: int64\n",
      "X364: int64\n",
      "X365: int64\n",
      "X366: int64\n",
      "X367: int64\n",
      "X368: int64\n",
      "X369: int64\n",
      "X370: int64\n",
      "X371: int64\n",
      "X372: int64\n",
      "X373: int64\n",
      "X374: int64\n",
      "X375: int64\n",
      "X376: int64\n",
      "X377: int64\n",
      "X378: int64\n",
      "X379: int64\n",
      "X380: int64\n",
      "X382: int64\n",
      "X383: int64\n",
      "X384: int64\n",
      "X385: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 4.1: Iterate through all the columns which has X in the name of the column\n",
    "\n",
    "# Filter columns with 'X' in the name\n",
    "x_columns = [col for col in X.columns if 'X' in col]\n",
    "\n",
    "# Iterate through the selected columns and print their data types\n",
    "print(\"Data Types of Columns with 'X':\")\n",
    "for col in x_columns:\n",
    "    print(f\"{col}: {X[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step5: Count the data in each of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Data in Each Column:\n",
      "X0      4209\n",
      "X1      4209\n",
      "X2      4209\n",
      "X3      4209\n",
      "X4      4209\n",
      "        ... \n",
      "X380    4209\n",
      "X382    4209\n",
      "X383    4209\n",
      "X384    4209\n",
      "X385    4209\n",
      "Length: 376, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the count of non-null values in each column\n",
    "column_counts = X.count()\n",
    "print(\"Count of Data in Each Column:\")\n",
    "print(column_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Read the test.csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Rows of Cleaned Test Data:\n",
      "    X0 X1  X2 X3 X4 X5 X6 X8  X10  X11  ...  X375  X376  X377  X378  X379  \\\n",
      "0  az  v   n  f  d  t  a  w    0    0  ...     0     0     0     1     0   \n",
      "1   t  b  ai  a  d  b  g  y    0    0  ...     0     0     1     0     0   \n",
      "2  az  v  as  f  d  a  j  j    0    0  ...     0     0     0     1     0   \n",
      "3  az  l   n  f  d  z  l  n    0    0  ...     0     0     0     1     0   \n",
      "4   w  s  as  c  d  y  i  m    0    0  ...     1     0     0     0     0   \n",
      "\n",
      "   X380  X382  X383  X384  X385  \n",
      "0     0     0     0     0     0  \n",
      "1     0     0     0     0     0  \n",
      "2     0     0     0     0     0  \n",
      "3     0     0     0     0     0  \n",
      "4     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 376 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming your file is named 'test.csv'\n",
    "test_file_path = './test.csv'\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "# Step 6.1: Remove columns ID and Y from the data\n",
    "# Assuming 'ID' and 'Y' are the columns to be removed\n",
    "columns_to_remove = ['ID', 'Y']\n",
    "test_data_cleaned = test_data.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Display the first few rows of the cleaned test data\n",
    "print(\"First 5 Rows of Cleaned Test Data:\\n\", test_data_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Check for null and unique values for test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values in Train Set:\n",
      " X0      0\n",
      "X1      0\n",
      "X2      0\n",
      "X3      0\n",
      "X4      0\n",
      "       ..\n",
      "X380    0\n",
      "X382    0\n",
      "X383    0\n",
      "X384    0\n",
      "X385    0\n",
      "Length: 376, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Values in Train Set:\n",
      " X0      47\n",
      "X1      27\n",
      "X2      44\n",
      "X3       7\n",
      "X4       4\n",
      "        ..\n",
      "X380     2\n",
      "X382     2\n",
      "X383     2\n",
      "X384     2\n",
      "X385     2\n",
      "Length: 376, dtype: int64\n",
      "\n",
      "Null Values in Test Set:\n",
      " X0      0\n",
      "X1      0\n",
      "X2      0\n",
      "X3      0\n",
      "X4      0\n",
      "       ..\n",
      "X380    0\n",
      "X382    0\n",
      "X383    0\n",
      "X384    0\n",
      "X385    0\n",
      "Length: 376, dtype: int64\n",
      "\n",
      "Unique Values in Test Set:\n",
      " X0      49\n",
      "X1      27\n",
      "X2      45\n",
      "X3       7\n",
      "X4       4\n",
      "        ..\n",
      "X380     2\n",
      "X382     2\n",
      "X383     2\n",
      "X384     2\n",
      "X385     2\n",
      "Length: 376, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in the training set\n",
    "print(\"Null Values in Train Set:\\n\", X.isnull().sum())\n",
    "\n",
    "# Check for unique values in the training set\n",
    "print(\"\\nUnique Values in Train Set:\\n\", X.nunique())\n",
    "\n",
    "# Check for null values in the test set\n",
    "print(\"\\nNull Values in Test Set:\\n\", test_data_cleaned.isnull().sum())\n",
    "\n",
    "# Check for unique values in the test set\n",
    "print(\"\\nUnique Values in Test Set:\\n\", test_data_cleaned.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: If for any column(s), the variance is equal to zero, then remove those variable(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with Zero Variance Removed in Training Set:\n",
      " Index(['X11', 'X93', 'X107', 'X233', 'X235', 'X268', 'X289', 'X290', 'X293',\n",
      "       'X297', 'X330', 'X347'],\n",
      "      dtype='object')\n",
      "Columns with Zero Variance Removed in Test Set:\n",
      " Index(['X11', 'X93', 'X107', 'X233', 'X235', 'X268', 'X289', 'X290', 'X293',\n",
      "       'X297', 'X330', 'X347'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Identify and remove columns with zero variance in the training set\n",
    "numeric_columns_train = X.select_dtypes(include=np.number).columns\n",
    "zero_variance_columns_train = X[numeric_columns_train].columns[X[numeric_columns_train].var() == 0]\n",
    "X = X.drop(columns=zero_variance_columns_train)\n",
    "print(\"Columns with Zero Variance Removed in Training Set:\\n\", zero_variance_columns_train)\n",
    "\n",
    "# Identify and remove the same columns with zero variance in the test set\n",
    "test_data_cleaned = test_data_cleaned.drop(columns=zero_variance_columns_train)\n",
    "print(\"Columns with Zero Variance Removed in Test Set:\\n\", zero_variance_columns_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Train Set (after label encoding):\n",
      "    X0  X1  X2  X3  X4  X5  X6  X8  X10  X12  ...  X375  X376  X377  X378  \\\n",
      "0  37  23  20   0   3  27   9  14    0    0  ...     0     0     1     0   \n",
      "1  37  21  22   4   3  31  11  14    0    0  ...     1     0     0     0   \n",
      "2  24  24  38   2   3  30   9  23    0    0  ...     0     0     0     0   \n",
      "3  24  21  38   5   3  30  11   4    0    0  ...     0     0     0     0   \n",
      "4  24  23  38   5   3  14   3  13    0    0  ...     0     0     0     0   \n",
      "\n",
      "   X379  X380  X382  X383  X384  X385  \n",
      "0     0     0     0     0     0     0  \n",
      "1     0     0     0     0     0     0  \n",
      "2     0     0     1     0     0     0  \n",
      "3     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 364 columns]\n",
      "\n",
      "Updated Test Set (after label encoding):\n",
      "    X0  X1  X2  X3  X4  X5  X6  X8  X10  X12  ...  X375  X376  X377  X378  \\\n",
      "0  37  23  20   0   3  27   9  14    0    0  ...     0     0     0     1   \n",
      "1  37  21  22   4   3  31  11  14    0    0  ...     0     0     1     0   \n",
      "2  24  24  38   2   3  30   9  23    0    0  ...     0     0     0     1   \n",
      "3  24  21  38   5   3  30  11   4    0    0  ...     0     0     0     1   \n",
      "4  24  23  38   5   3  14   3  13    0    0  ...     1     0     0     0   \n",
      "\n",
      "   X379  X380  X382  X383  X384  X385  \n",
      "0     0     0     0     0     0     0  \n",
      "1     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0  \n",
      "3     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 364 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you want to apply label encoding to categorical columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify categorical columns for label encoding in the training set\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Concatenate the training and test sets for consistent label encoding\n",
    "combined_data = pd.concat([X, test_data_cleaned], axis=0)\n",
    "\n",
    "# Reset index of the combined_data DataFrame\n",
    "combined_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Apply label encoding to categorical columns in the combined dataset\n",
    "for col in categorical_columns:\n",
    "    combined_data[col] = label_encoder.fit_transform(combined_data[col])\n",
    "\n",
    "# Apply label encoding to categorical columns in the training set\n",
    "for col in categorical_columns:\n",
    "    X[col] = combined_data.loc[X.index, col]\n",
    "\n",
    "# Apply label encoding to categorical columns in the test set\n",
    "for col in categorical_columns:\n",
    "    test_data_cleaned[col] = combined_data.loc[test_data_cleaned.index, col]\n",
    "\n",
    "# Display the first few rows of the updated train and test sets\n",
    "print(\"\\nUpdated Train Set (after label encoding):\\n\", X.head())\n",
    "print(\"\\nUpdated Test Set (after label encoding):\\n\", test_data_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Make sure the data is now changed into numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types after Label Encoding:\n",
      " X0      int32\n",
      "X1      int32\n",
      "X2      int32\n",
      "X3      int32\n",
      "X4      int32\n",
      "        ...  \n",
      "X380    int64\n",
      "X382    int64\n",
      "X383    int64\n",
      "X384    int64\n",
      "X385    int64\n",
      "Length: 364, dtype: object\n",
      "\n",
      "Non-Numeric Columns Remaining:\n",
      " Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the data types of each column\n",
    "print(\"Data Types after Label Encoding:\\n\", test_data_cleaned.dtypes)\n",
    "\n",
    "# Check for any remaining non-numeric columns\n",
    "non_numeric_columns_remaining = test_data_cleaned.select_dtypes(exclude=np.number).columns\n",
    "print(\"\\nNon-Numeric Columns Remaining:\\n\", non_numeric_columns_remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Perform dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio after SVD:\n",
      " [0.24565996 0.32999136 0.16391651 0.11337014 0.08648512 0.01796575\n",
      " 0.00705483 0.00468904 0.00339067 0.00248953]\n",
      "\n",
      "Shape of Reduced Train Set after SVD: (4209, 10)\n",
      "Shape of Reduced Test Set after SVD: (4209, 10)\n"
     ]
    }
   ],
   "source": [
    "# Step 10.1: Linear dimensionality reduction using Singular Value Decomposition (SVD)\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Specify the number of components for dimensionality reduction\n",
    "n_components_svd = 10  # Adjust as needed\n",
    "\n",
    "# Step 10.1: Apply SVD to training set\n",
    "svd = TruncatedSVD(n_components=n_components_svd)\n",
    "X_svd = svd.fit_transform(X)\n",
    "\n",
    "# Check if the number of features in the test set matches the training set\n",
    "if X.shape[1] == test_data_cleaned.shape[1]:\n",
    "    # Apply SVD to test set\n",
    "    test_data_svd = svd.transform(test_data_cleaned)\n",
    "\n",
    "    # Display the explained variance ratio\n",
    "    print(\"Explained Variance Ratio after SVD:\\n\", svd.explained_variance_ratio_)\n",
    "\n",
    "    # Display the shape of the reduced train and test sets\n",
    "    print(\"\\nShape of Reduced Train Set after SVD:\", X_svd.shape)\n",
    "    print(\"Shape of Reduced Test Set after SVD:\", test_data_svd.shape)\n",
    "else:\n",
    "    print(\"Number of features in the training set and test set do not match.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step11: Training using xgboost \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:11.75450\n",
      "[10]\tvalidation-rmse:8.52281\n",
      "[20]\tvalidation-rmse:8.13722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [13:08:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\tvalidation-rmse:8.17701\n",
      "[40]\tvalidation-rmse:8.28537\n",
      "[50]\tvalidation-rmse:8.29410\n",
      "[60]\tvalidation-rmse:8.34715\n",
      "[70]\tvalidation-rmse:8.38759\n",
      "[71]\tvalidation-rmse:8.39184\n",
      "Validation RMSE: 8.398574652037023\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 11: Training using xgboost\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the datasets into DMatrix format, which is the internal data structure that XGBoost uses\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "# Define the XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',  # Regression task with squared error\n",
    "    'eval_metric': 'rmse',  # Root Mean Squared Error as the evaluation metric\n",
    "    'max_depth': 6,  # Maximum depth of a tree\n",
    "    'learning_rate': 0.1,  # Step size shrinkage used in each boosting step\n",
    "    'subsample': 0.8,  # Fraction of samples used for training trees\n",
    "    'colsample_bytree': 0.8,  # Fraction of features used for training trees\n",
    "    'n_estimators': 100  # Number of boosting rounds\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "model = xgb.train(params, dtrain, num_boost_round=1000, evals=[(dvalid, 'validation')], early_stopping_rounds=50, verbose_eval=10)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(dvalid)\n",
    "\n",
    "# Calculate and print the Root Mean Squared Error (RMSE) on the validation set\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "print(f\"Validation RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12: Predict your test_df values using xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values for Test Set:\n",
      " [ 78.356125  94.23115   78.453896 ...  91.43997  116.34771   92.12124 ]\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Predict your test_df values using xgboost\n",
    "\n",
    "# Convert the test dataset into DMatrix format\n",
    "dtest = xgb.DMatrix(test_data_cleaned)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(dtest)\n",
    "\n",
    "# Display the predicted values for the test set\n",
    "print(\"Predicted Values for Test Set:\\n\", test_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
